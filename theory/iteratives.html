<!DOCTYPE html>
<head>
  <meta charset="utf-8">
  <link rel="stylesheet" type="text/css" href="../style_notes.css">
  <title>Métodos Directos</title>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.1/es5/tex-mml-chtml.js"></script>
</head>
<body>
<h1 class="text">Métodos iterativos.</h1>
<p>A diferencia de los métodos directos como la triangulación Gauss o la
factorización LU que una vez que terminan nos dan el valor de la
solución directamente (o con un error pequeño debido a la precisión
finita del ordenador) en los métodos iterativos de resolución de
sistemas de ecuaciones se crea una sucesión de aproximaciones a la
solución, que converge a la solución exacta.
</p>
<p>Es decir, dado el sistema compatible determinado:
</p>
<div class="formula">
  \[
  \mathbf{A}\mathbf{x}=\mathbf{b}
  \]
</div>
<p>cuya solución exacta es \(\mathbf{x}=\mathbf{A}^{-1}\mathbf{b}\),
construyen una sucesión:
</p>
<div class="formula">
  \[
  \left\lbrace\mathbf{x}_i\right\rbrace=\mathbf{x}_0,\mathbf{x}_1,\dots
  \]
</div>
<p>de aproximaciones a la solución, a partir de una aproximación inicial
\(\mathbf{x}_0\), tal que
</p>
<div class="formula">
  \[
  \lim_{i\to\infty}\mathbf{x}_i=\mathbf{x}
  \]
</div>
<p>En los métodos iterativos lineales la regla que nos permite obtener la
aproximación \(\mathbf{x}_{i+1}\) a partir de la aproximación
\(\mathbf{x}_{i}\) será una regla de recurrencia de la forma:</p>
\[
\label{eq:reclineales}
\mathbf{x}_{i+1} = \mathbf{M}\mathbf{x}_{i} + \mathbf{c}
\tag{1}\]
<p>donde \(\mathbf{M}\) es una matriz \(N\times N\) y \(\mathbf{c}\) es
un vector columna de \(N\) elementos.
</p>
<p>Si el método converge a un límite \(\mathbf{x}\) se tiene que la
solución exacta será aquella que cumpla que:</p>
<div class="formula">
  \[
  \label{eq:sol}
  \mathbf{x} = \mathbf{M}\mathbf{x} + \mathbf{c}
  \tag{2}
  \]
</div>
<p>Se define el vector error en la aproximación \(i\)-ésima como:
</p>
<div class="formula">
  \[
  \mathbf{e}_{i}=\mathbf{x}-\mathbf{x}_i
  \]
</div>
<p>y restando las ecuaciones (\ref{eq:sol}) y (\ref{eq:reclineales}) se obtiene su regla de recurrencia:
</p>
<div class="formula">
  \[
  \mathbf{e}_{i+1}  = \mathbf{M}\mathbf{e}_i
  \]
</div>
<p>que también nos da la expresión general conocido \(\mathbf{e}_0\):
</p>
<div class="formula">
  \[
  \mathbf{e}_{i+1}  = \mathbf{M}\left(\mathbf{M}\mathbf{e}_{i-1}\right)=\dots = \mathbf{M}^{i+1}\mathbf{e}_0
  \]
</div>
<p>Teniendo en cuenta la definición de la norma \(2\) de una matriz se
puede acotar la norma del error en la aproximación \(i+1\) a partir del
error inicial \(\mathbf{e}_0\):
</p>
<div class="formula">
  \[
  \Vert\mathbf{e}_{i+1}\Vert_2  = \Vert\mathbf{M}\mathbf{e}_i\Vert_2\le\Vert\mathbf{M}\Vert_2\Vert\mathbf{e}_i\Vert_2\le\Vert\mathbf{M}\Vert^{i+1}_2\Vert\mathbf{e}_0\Vert_2
  \]
</div>
<p>Por lo tanto, si
\(\Vert\mathbf{M}\Vert_2=\sigma_\mathrm{max}\left(\mathbf{M}\right)\lt1\)
se tiene que:</p>
<div class="">
  \[
  \lim_{i\to\infty}\Vert\mathbf{e}_{i}\Vert_2  \le\lim_{i\to\infty}\Vert\mathbf{M}\Vert^i_2\Vert\mathbf{e}_0\Vert_2=0
  \]
</div>
<p>con lo que se puede asegurar que el método converge a la solución
exacta. En general, cuanto menor sea la norma de la matriz
\(\mathbf{M}\) más rápido se podrá asegurar que converge el método.</p>
<h2 class="text">Criterios de parada.</h2>
<p>En todo método iterativo es necesario establecer unos criterios de
parada, pues sino el programa iteraría infinitamente.
</p>
<p>Existen tres criterios principales para decidir si se debe seguir
iterando.
</p>
<p>El primero de ellos es el mas simple, y es que independientemente de que
la solución sea buena o no, puede que no se quiera que el programa se
quede funcionando mas de un cierto tiempo, o lo que es lo mismo, que
como máximo se realicen \(N_\mathrm{max}\) iteraciones.
</p>
<p>Los otros dos criterios hacen referencia a la posibilidad de que se
alcance una solución aproximada suficientemente buena antes de realizar
\(N_\mathrm{max}\).
</p>
<p>En primer lugar se puede comprobar si \(\mathbf{x}_{n+1}\) está
suficientemente cerca del límite. Para ello se comprueba si la
diferencia es menor que un cierto valor pequeño en términos absolutos</p>
<div class="formula">
 \[
 \Vert\mathbf{x}_{n+1}-\mathbf{x}_{n}\Vert<\epsilon
 \]
</div>
<p> o en términos relativos</p>
<div class="formula">
 \[
 \frac{\Vert\mathbf{x}_{n+1}-\mathbf{x}_{n}\Vert}{\Vert\mathbf{x}_n\Vert}<\epsilon
 \]
</div>
<p>donde \(\Vert\Vert\) hace referencia a cualquiera de las normas
vectoriales explicadas. Dependiendo del problema puede ser interesante
una norma u otra.</p>
<p>Otra opción es comprobar que el residuo de la ecuación es
suficientemente pequeño. El residuo en la iteración \(n\) se define
como:</p>
<div class="formula">
  \[
  R_n =\Vert\mathbf{b}-\mathbf{A}\mathbf{x}_n\Vert\ge 0
  \]
</div>
<p>donde \(\Vert\Vert\) vuelve a ser cualquier norma.
</p>
<p>La condición que se impondría sería que:</p>
<div class="formula">
 \[
 R_n \le \epsilon
 \]
</div>
<p>y su significado sería pedir que \(\mathbf{x}_n\) esté
suficientemente cerca de cumplir la ecuación, pues para la solución
exacta \(\mathbf{x}\) el residuo es cero (en cualquier norma).</p>
<p>En sistemas lineales ambos criterios son completamente equivalentes por lo que solo se usará uno,
pero como se verá más adelante, en ecuaciones no lineales en general son criterios independientes.</p>

<h2 class="text">Método de Jacobi.</h2>
<p>Si se tiene el sistema \(\mathbf{A}\mathbf{x} = \mathbf{b}\), se puede
separar la matriz \(\mathbf{A}\) como suma de una matriz triangular
inferior, una diagonal, y una triangular superior:
</p>
<div class="formula">
  \[
  \begin{pmatrix}
  a_{11} & a_{12} &\dots& a_{1N}\\
  a_{21} & a_{22} &\dots& a_{2N}\\
  \vdots & \vdots &\ddots& \vdots\\
  a_{N1} & a_{N2} &\dots& a_{NN}\\
  \end{pmatrix}
  =\begin{pmatrix}
  0 & 0 &\dots& 0\\
  a_{21} & 0 &\dots& 0\\
  \vdots & \vdots &\ddots& \vdots\\
  a_{N1} & \dots &a_{N,N-1}& 0\\
  \end{pmatrix}+\begin{pmatrix}
  a_{11} & 0 &\dots& 0\\
  0 & a_{22} &\ddots& \vdots\\
  \vdots & \ddots &\ddots& 0\\
  0 & \dots & 0 & a_{NN}\\
  \end{pmatrix}+\begin{pmatrix}
  0 & a_{12} &\dots& a_{1N}\\
  0 & 0 &\ddots& \vdots\\
  \vdots & \vdots &\ddots& a_{N-1,N}\\
  0 & 0 &\dots& 0\\
  \end{pmatrix}
  \]
</div>
<p>con lo que el sistema se puede reordenar como:</p>
<div class="formula">
  \[
  \mathbf{D}\mathbf{x}=-\left(\mathbf{L}+\mathbf{U}\right)\mathbf{x}+\mathbf{b}
  \]
</div>
<p>o bien</p>
<div class="formula">
  \[
  \mathbf{x}=-\mathbf{D}^{-1}\left(\mathbf{L}+\mathbf{U}\right)\mathbf{x}+\mathbf{D}^{-1}\mathbf{b}
  \]
</div>
<p>El método de Jacobi utiliza precisamente la expresión anterior para
iterar, es decir, dada la primera solución aproximada \(\mathbf{x}_0\),
el método de Jacobi construye la sucesión mediante la relación de
recurrencia:
</p>
<div class="formula">
  \[
  \mathbf{x}_{i+1} =  -\mathbf{D}^{-1}\left(\mathbf{L}+\mathbf{U}\right)\mathbf{x}_i+\mathbf{D}^{-1}\mathbf{b}
  \]
</div>
<p>Si se identifican términos con la expresión genérica de los métodos
iterativos lineales (\ref{eq:reclineales}), se observa que</p>
<div class="formula">
  \[
  \mathbf{M}=-\mathbf{D}^{-1}\left(\mathbf{L}+\mathbf{U}\right)
  \]
</div>
<p>por lo tanto si \(\Vert\mathbf{D}^{-1}\left(\mathbf{L}+\mathbf{U}\right)\Vert_2\lt1\) el
método de Jacobi convergerá a la solución independientemente de la aproximación inicial dada.
</p>

<!-- \begin{lstlisting}
    function Jacobi(A,b,x_0, maxIter, err_x) result(x)
      real, intent(in) :: A(:,:), b(:), x_0(:)
      integer, intent(in) :: maxIter
      real, intent(in) :: err_x
      real :: x(size(A,2))

      integer :: i, N
      real :: L(size(A,1),size(A,2)),U(size(A,1),size(A,2))
      real :: x_old(size(A,2)), D_inv(size(A,2))

      N = size(A,2)

      L = 0
      U = 0
      do i = 1, N
        L(i,1:i-1)=A(i,1:i-1)
        D_inv(i) = 1./A(i,i)
        U(i,i+1:N) = A(i,i+1:N)
      end do

      x_old = x_0
      do i = 1, maxIter
        x = -D_inv*MATMUL(L+U,x_old)+D_inv*b
        if ( norm2(x-x_old)/norm2(x) < err_x ) exit
        x_old = x
      end do
      if( i>maxIter ) then
       print*, 'se ha alcanzado el maximo de iteraciones'
      end if
    end function
\end{lstlisting} -->

<h2 class="text">Método de Gauss-Seidel.</h2>
<p>Si en cambio se separa la matriz \(\mathbf{A}\) como suma de una
triangular superior y una triangular inferior, quedándose la diagonal en
la inferior:</p>
<div class="formula">
  \[
  \begin{pmatrix}
  a_{11} & a_{12} &\dots& a_{1N}\\
  a_{21} & a_{22} &\dots& a_{2N}\\
  \vdots & \vdots &\ddots& \vdots\\
  a_{N1} & a_{N2} &\dots& a_{NN}\\
  \end{pmatrix}
  =\begin{pmatrix}
  a_{11} & 0 &\dots& 0\\
  a_{21} & a_{22} &\dots& \vdots\\
  \vdots & \ddots &\ddots& 0\\
  a_{N1} & \dots &a_{N,N-1}& a_{NN}\\
  \end{pmatrix}+\begin{pmatrix}
  0 & a_{12} &\dots& a_{1N}\\
  0 & 0 &\ddots& \vdots\\
  \vdots & \vdots &\ddots& a_{N-1,N}\\
  0 & 0 &\dots& 0\\
  \end{pmatrix}
  \]
</div>
<p>el sistema lo podemos reordenar como:
</p>
<div class="formula">
  \[
  \left(\mathbf{L}+\mathbf{D}\right)\mathbf{x}=-\mathbf{U}\mathbf{x}+\mathbf{b}
  \]
</div>
<p>donde \(\mathbf{L}+\mathbf{D}\) es la matriz triangular inferior que contiene a la diagonal.
</p>
<p>El método de Gauss-Seidel, dada la primera solución aproximada
\(\mathbf{x}_0\), construye la sucesión mediante la relación de
recurrencia:
</p>
<div class="formula">
  \[
  \left(\mathbf{L}+\mathbf{D}\right)\mathbf{x}_{i+1}=-\mathbf{U}\mathbf{x}_i+\mathbf{b}
  \]
</div>
<p>es decir, en cada iteración resuelve el sistema anterior para obtener \(\mathbf{x}_{i+1}\) a partir \(\mathbf{x}_i\).
</p>
<p>Si se identifican términos con la expresión genérica de los métodos
iterativos lineales, se observa que</p>
<div class="formula">
  \[
  \mathbf{M}=-\left(\mathbf{L}+\mathbf{D}\right)^{-1}\mathbf{U}
  \]
</div>
<p>por lo tanto si \(\Vert\left(\mathbf{L}+\mathbf{D}\right)^{-1}\mathbf{U}\Vert_2\lt 1\) el
método de Gauss-Seidel convergerá a la solución independientemente de la
aproximación inicial dada.</p>

<!-- \begin{lstlisting}
    function GaussSeidel(A,b,x_0, maxIter, err_x) result(x)
      real, intent(in) :: A(:,:), b(:), x_0(:)
      integer, intent(in) :: maxIter
      real, intent(in) :: err_x
      real :: x(size(A,2))

      integer :: i, N
      real :: LD(size(A,1),size(A,2)), U(size(A,1),size(A,2))
      real :: x_old(size(A,2))

      N = size(A,2)

      LD = 0
      U = 0
      do i = 1, N
        LD(i,  1:i) = A(i,  1:i)
        U (i,i+1:N) = A(i,i+1:N)
      end do

      x_old = x_0
      do i = 1, maxIter
        x = solve_L(LD,-MATMUL(U,x_old)+b)
        if ( norm2(x-x_old)/norm2(x) < err_x ) exit
        x_old = x
      end do
      if( i>maxIter ) then
      	print*, 'se ha alcanzado el maximo de iteraciones'
      end if
    end function
\end{lstlisting} -->
</body>
