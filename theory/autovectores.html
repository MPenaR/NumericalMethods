<!DOCTYPE html>
<head>
    <meta charset="utf-8">
    <link rel="stylesheet" type="text/css" href="../style_notes.css">
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.1/es5/tex-mml-chtml.js"></script>
    <title>Autovalores</title>
</head>
<body>
<h1>Autovalores y autovectores.</h1> 
<p>Dada una matriz cuadrada real \(\mathbf{A}\), un autovector \(\mathbf{v}\) es un vector distinto del vector nulo que cumple:
</p>
<div class="formula">
    \[
    \label{eq:def_eig}
    \mathbf{A}\mathbf{v}=\lambda\mathbf{v}
    \tag{1}
    \]
</div>
<p>
    para algún valor real \(\lambda\).
    
    Es decir, es un vector que al ser multiplicado por la matriz \(\mathbf{A}\) es transformado en un vector proporcional a si mismo, \(\lambda\mathbf{v}\).
</p>
<p>
    La constante de proporcinalidad \(\mathbf{\lambda}\) se conoce como autovalor asociado al autovector \(\mathbf{v}\).
</p>


<p>Si operamos en la ecuación (\ref{eq:def_eig}) obtenemos otra forma de definir a los autovectores. Son las soluciones no triviales del sistema
</p>
<div class="formula">
    \[
    \label{system}
    \left(\mathbf{A}−\lambda\mathbf{I}\right)\mathbf{v}=0
    \tag{2}
    \]
</div>
<p>   
    para ciertos \(\lambda\). Es decir, para ciertos valores de \(\lambda\) (los llamados autovalores) el sistema (\ref{system}) será compatible indeterminado, y por lo tanto admitirá infinitas soluciones \(\mathbf{v}\), distintas de la solución trivial \(\mathbf{0}\), que serán los autovectores asociados al autovalor \(\lambda\).
</p>    

<p>El sistema (\ref{system}) será indeterminado si y solo si</p>
<div class="formula">
    \[
    \label{det}
    \det\left(\mathbf{A}-\lambda\mathbf{I}\right)=0
    \tag{3}
    \]
</div>
<p>
    por lo que el método de cálculo de autovalores y autovectores dado en álgebra consiste en:
    <ol>
        <li>calcular los \(\lambda_i\) autovalores como las soluciones de la ecuación (\ref{det}).</li>
        <li>para cada \(\lambda_i\) buscar las soluciones distintas del vector nulo, del sistema indeterminado \(\left(\mathbf{A} - \lambda_i\mathbf{I}\right)\mathbf{v} = \mathbf{0}\)</li>
    </ol>
</p>
<p>
    El método anterior puede funcionar para matrices pequeñas, pero para matrices grandes supone un problema. En primer lugar, si la matriz \(\mathbf{A}\) es una matriz \(N\times N\), la ecuacion (\ref{det}) será una ecuación de grado \(N\). Para \(N\ge5\) no existe la formula general de las soluciónes de esa ecuación en función de sus coeficientes. En segundo lugar, si \(N\) es muy grande, calcular su determinante para poder obtener la eucación será muy costoso.
</p>

<p>
    En este tema se explicará el método de la potencia, el cual nos permite hayar el autovector asociado al autovalor de módulo máximo mediante un proceso iterativo, y el método de la potencia inversa, que, modificando el método de la potencia; es capaz de darnos el autovector asociado al autovalor mas cercano a un cierto valor.
</p>

<h2>Método de la potencia.</h2>
<p>
    Sea \(\mathbf{A}\) una matriz diagonalizable de tamaño \(N\) y sean \(\lambda_1,\lambda_2,\dots,\lambda_N\) sus autovalores. Podemos suponer sin pérdida de generalidad que los autovalores están ordenados de mayor a menor módulo, es decir:
    \[|\lambda_1|\ge|\lambda_2|\ge\dots\ge|\lambda_N|\]
    Si se cumple que \(|\lambda_1|>|\lambda_2|\) se dirá que la matriz posee un autovalor de módulo máximo que se denotará por \(\lambda_\mathrm{max}=\lambda_1\).
</p>

<p>
    El método de la potencia es un método iterativo para calcular el  autovector asociado a este autovalor máximo que se basa en el hecho de que si la matriz es diagonalizable, los autovectores forman una base ortonormal (ortogonales y de módulo unitario) del espacio espacio vectorial \(\mathbb{R}^N\).
</p>

<p>
    Sea \(\mathbf{u}_0\in\mathbb{R}^N\) un vector cualquiera, y sean \(\mathbf{v}_1,\mathbf{v}_2,\dots,\mathbf{v}_N\) los autovectores de la matriz \(\mathbf{A}\). Puesto que los autovectores forman una base de \(\mathbb{R}^N\) podemos expresar al vector \(\mathbf{u}_0\) en esa base como:
    \[
    \mathbf{u}_0=q_1\mathbf{v}_1 + q_2\mathbf{v}_2 + \dots + q_N\mathbf{v}_N=\sum_{i=1}^Nq_i\mathbf{v}_i
    \]
</p>

<p>
    Si se multiplica la matriz \(\mathbf{A}\) por el vector \(\mathbf{u}_0\) se obtiene:
    \[
    \mathbf{A}\mathbf{u}=q_1\lambda_1\mathbf{v}_1 + q_2\lambda_2\mathbf{v}_2 + \dots + q_N\lambda_N\mathbf{v}_N=\sum_{i=1}^Nq_i\lambda_i\mathbf{v}_i
    \]
    donde se ha usado el hecho de que los vectores \(\mathbf{v}_i\) son autovectores de la matriz \(\mathbf{A}\).    
</p>
<p>
    Teniendo en cuenta que la base de vectores es ortonormal, la norma 2 será:
    \[
    \Vert\mathbf{A}\mathbf{u}_0\Vert_2=\sqrt{\left(q_1\lambda_1\right)^2+\left(q_2\lambda_2\right)^2+\dots+\left(q_N\lambda_N\right)^2 }=\sqrt{\sum_{i=1}^N\left(q_i\lambda_i\right)^2}
    \]    
</p>
<p>
    Se llamará \(\mathbf{u}_1\) al vector \(\mathbf{A}\mathbf{u}_0\) normalizado, es decir:
    \[
    \mathbf{u}_1=\frac{\mathbf{A}\mathbf{u}_0}{\Vert\mathbf{A}\mathbf{u}_0\Vert_2}=\frac{q_1\lambda_1\mathbf{v}_1 + q_2\lambda_2\mathbf{v}_2 + \dots + q_N\lambda_N\mathbf{v}_N}{\sqrt{\left(q_1\lambda_1\right)^2+\left(q_2\lambda_2\right)^2+\dots+\left(q_N\lambda_N\right)^2 }}=\frac{\sum_{i=1}^Nq_i\lambda_i\mathbf{v}_i}{\sqrt{\sum_{i=1}^N\left(q_i\lambda_i\right)^2}}
    \]
</p>
<p>
    Si repetimos el proceso se obtiene:
    \[\mathbf{A}\mathbf{u}_1=\frac{\mathbf{A}^2 \mathbf{u_0}}{\Vert\mathbf{A}\mathbf{u}_0\Vert_2}=\frac{q_1\lambda^2_1\mathbf{v}_1 + q_2\lambda^2_2\mathbf{v}_2 + \dots + q_N\lambda^2_N\mathbf{v}_N}{\sqrt{\left(q_1\lambda_1\right)^2+\left(q_2\lambda_2\right)^2+\dots+\left(q_N\lambda_N\right)^2 }}=\frac{\sum_{i=1}^Nq_i\lambda^2_i\mathbf{v}_i}{\sqrt{\sum_{i=1}^N\left(q_i\lambda_i\right)^2}}\]
    y para el módulo
    \[\Vert\mathbf{A}\mathbf{u}_1\Vert_2=\frac{\Vert\mathbf{A}^2 \mathbf{u_0}\Vert_2}{\Vert\mathbf{A}\mathbf{u}_0\Vert_2}=\frac{\sqrt{\left(q_1\lambda^2_1\right)^2+\left(q_2\lambda^2_2\right)^2+\dots+\left(q_N\lambda^2_N\right)^2 }}{\sqrt{\left(q_1\lambda_1\right)^2+\left(q_2\lambda_2\right)^2+\dots+\left(q_N\lambda_N\right)^2 }}=\frac{\sqrt{\sum_{i=1}^N\left(q_i\lambda^2_i\right)^2}}{\sqrt{\sum_{i=1}^N\left(q_i\lambda_i\right)^2}}\]    
</p>
<p>
    Con lo que
    \[\mathbf{u}_2=\frac{\mathbf{A}\mathbf{u}_1}{\Vert\mathbf{A}\mathbf{u}_1\Vert_2}=\frac{\frac{\mathbf{A}^2 \mathbf{u_0}}{\Vert\mathbf{A}\mathbf{u}_0\Vert_2}}{\frac{\Vert\mathbf{A}^2 \mathbf{u_0}\Vert_2}{\Vert\mathbf{A}\mathbf{u}_0\Vert_2}}=\frac{\mathbf{A}^2 \mathbf{u_0}}{\Vert\mathbf{A}^2 \mathbf{u_0}\Vert_2}=\frac{q_1\lambda^2_1\mathbf{v}_1 + q_2\lambda^2_2\mathbf{v}_2 + \dots + q_N\lambda^2_N\mathbf{v}_N}{\sqrt{\left(q_1\lambda^2_1\right)^2+\left(q_2\lambda^2_2\right)^2+\dots+\left(q_N\lambda^2_N\right)^2 }}=\frac{\sum_{i=1}^Nq_i\lambda^2_i\mathbf{v}_i}{\sqrt{\sum_{i=1}^N\left(q_1\lambda^2_1\right)^2 }}\]
    y en general se tiene que
    \[
    \mathbf{u}_n = \frac{q_1\lambda^n_1\mathbf{v}_1 + q_2\lambda^n_2\mathbf{v}_2 + \dots + q_N\lambda^n_N\mathbf{v}_N}{\sqrt{\left(q_1\lambda^n_1\right)^2+\left(q_2\lambda^n_2\right)^2+\dots+\left(q_N\lambda^n_N\right)^2 }}=\frac{\sum_{i=1}^Nq_i\lambda^n_i\mathbf{v}_i}{\sqrt{\sum_{i=1}^N\left(q_1\lambda^n_1\right)^2 }}
    \]    
</p>
<p>
    Por último, teniendo en cuenta que \(\lambda_1=\lambda_\mathrm{max}\) se tiene que \(\vert\frac{\lambda_i}{\lambda_1}\vert\lt 1\), para todo \(i\gt 1\), por lo tanto, podemos asegurar que siempre que \(q_1\neq0\), es decir, siempre que nuestro vector inicial \(\mathbf{u}_0\) tenga una componente según \(\mathbf{v}_1\) no nula, se tendrá que
    \[\boxed{
    \lim_{n\to\infty}\mathbf{u}_n=\mathbf{v}_1}
    \]
    es decir, la sucesión de vectores unitarios obtenida a partir de \(\mathbf{u}_0\), multiplicando por la matriz \(\mathbf{A}\) y normalizando, tiende al autovector asociado al autovalor de módulo máximo a medida que \(n\) tiende a infinito. 
</p>
<h2>Método de la potencia inversa.</h2>
<p>El método de la potencia sólo sirve para calcular el autovector asociado al autovalor de máximo módulo absoluto de una matriz \(\mathbf{A}\), sin embargo, como vamos a ver, se puede aplicar este método a una matriz dependiente de \(\mathbf{A}\) de forma que obtengamos el autovector deseado.</p>
<p>Supongamos que \(\mathbf{A}\) es una matriz invertible, diagonalizable con \(N\) autovalores \(\lambda_i\) y autovectores asociados \(\mathbf{v}_i\). En ese caso se tiene que:</p>
<div class="formula">
    \[
    \mathbf{A}\mathbf{v}_i = \lambda_i\mathbf{v}_i
    \]
</div>
<p>Si premultiplicamos por la matriz inversa de \(\mathbf{A}\) y dividimos por \(\lambda_i\) se obtiene:</p>
<div>
    \[
    \frac{1}{\lambda_i}\mathbf{v}_i=\mathbf{A}\mathbf{v}_i
    \]
</div>
<p>Lo que acabamos de demostrar es que la matriz \(\mathbf{A}^{-1}\) tiene los mismos autovectores que la matriz \(\mathbf{A}\), con la diferencia que el autovalor asociado a cada autovector \(\mathbf{v}_i\) en este caso será \(1/\lambda_i\).</p>
<p>Vamos a analizar lo que le ocurre a la matriz \(\mathbf{A}-\mu\mathbf{I}\), siendo \(\mu\) una constante cualquiera. Si multiplicamos esa matriz por un autovector \(\mathbf{v}_i\) de la matriz \(\mathbf{A}\) obtenemos:</p>
<div class="formula">
\[
\left(\mathbf{A}-\mu\mathbf{I}\right)\mathbf{v}_i=\mathbf{A}\mathbf{v}_i-\mu\mathbf{I}\mathbf{v}_i=\lambda_i\mathbf{v}_i-\mu\mathbf{v}_i=\left(\lambda_i-\mu\right)\mathbf{v}_i
\]
</div>
<p>Es decir, acabamos de demostrar que la matriz \(\mathbf{A}-\mu\mathbf{I}\) tiene los mismos autovectores que la matriz \(\mathbf{A}\) y sus autovalores asociados son \(\lambda_i-\mu\).</p>
<p>Juntando los dos resultados anteriores se demuestra fácilmente que la matriz \(\mathbf{B}_\mu = \left(\mathbf{A}-\mu\mathbf{I}\right)^{-1}\) tendrá los mismos autovectores que la matriz \(\mathbf{A}\) y sus autovalores asociados serán \(\frac{1}{\lambda_i-\mu}\). Este resultado nos será muy útil, pues significa que, escogiendo un valor de \(\mu\) suficientemente cercano a uno de los autovalores de \(\mathbf{A}\), podremos hacer que el autovalor correspondiente de la matriz \(\mathbf{B}_\mu\) sea tan grande como nosotros queramos. De este modo, aplicando el método de la potencia a la matriz \(\mathbf{B}_\mu\) obtendremos el autovector de la matriz \(\mathbf{A}\) asociado al autovalor \(\lambda_i\) más cercano a \(\mu\).</p>
</body>